#pragma once
#ifndef __STDHDR_CGH_A5B2945F_539F_4023_835B_6A509BAD191E__
#define __STDHDR_CGH_A5B2945F_539F_4023_835B_6A509BAD191E__
// SPDX-FileCopyrightText: (c) 2022 The niLang Authors
// SPDX-License-Identifier: MIT

#include "StdDefs.cgh"
#include "StdPixelInput.cgh"
#include "StdUniforms.cgh"
#include "StdSampler.cgh"

// The per-color weighting to be used for blue shift under low light.
static const float3 kHDR_BlueShiftVector  = float3(1.05f, 0.97f, 1.27f);

static const int    kHDR_MaxSamples          = 16;    // Maximum texture grabs
// The per-color weighting to be used for luminance calculations in RGB order.
static const float3 kHDR_LuminanceVector    = float3(0.2125f, 0.7154f, 0.0721f);

uniform float2 uHDR_SampleOffsets[kHDR_MaxSamples];
uniform float4 uHDR_SampleWeights[kHDR_MaxSamples];
uniform float4 uHDR_MergeCount;

uniform float4 uHDR_Params; // middleGray, brightPassThreshold, brightPassOffset, adaptationSpeed
#define HDR_MIDDLE_GRAY       uHDR_Params.x
#define HDR_BRIGHT_PASS_THRESHOLD uHDR_Params.y
#define HDR_BRIGHT_PASS_OFFSET    uHDR_Params.z
#define HDR_ADAPTATION_SPEED    uHDR_Params.w

uniform float4 uHDR_Scales; // bloomScale, starScale, colorScale, whiteLuminance
#define HDR_BLOOM_SCALE     uHDR_Scales.x
#define HDR_STAR_SCALE      uHDR_Scales.y
#define HDR_COLOR_SCALE     uHDR_Scales.z
#define HDR_WHITE_LUM     uHDR_Scales.w

// M matrix, for encoding
static const float3x3 kLoguv_M = float3x3(
    0.2209, 0.3390, 0.4184,
    0.1138, 0.6780, 0.7319,
    0.0102, 0.1130, 0.2969);

// Inverse M matrix, for decoding
static const float3x3 kLoguv_InverseM = float3x3(
    6.0013, -2.700, -1.7995,
    -1.332, 3.1029, -5.7720,
    .3007,  -1.088, 5.6268);

///////////////////////////////////////////////
float4 stdHDR_LogLuvEncode(in float3 vRGB)  {
  float4 vResult;
  float3 Xp_Y_XYZp = mul(vRGB, kLoguv_M);
  Xp_Y_XYZp = max(Xp_Y_XYZp, float3(1e-6, 1e-6, 1e-6));
  vResult.xy = Xp_Y_XYZp.xy / Xp_Y_XYZp.z;
  float Le = 2 * log2(Xp_Y_XYZp.y) + 127;
  vResult.w = frac(Le);
  vResult.z = (Le - (floor(vResult.w*255.0f))/255.0f)/255.0f;
  return vResult;
}

///////////////////////////////////////////////
float3 stdHDR_LogLuvDecode(in float4 vLogLuv) {
  float Le = vLogLuv.z * 255 + vLogLuv.w;
  float3 Xp_Y_XYZp;
  Xp_Y_XYZp.y = exp2((Le - 127) / 2);
  Xp_Y_XYZp.z = Xp_Y_XYZp.y / vLogLuv.y;
  Xp_Y_XYZp.x = vLogLuv.x * Xp_Y_XYZp.z;
  float3 vRGB = mul(Xp_Y_XYZp, kLoguv_InverseM);
  return max(vRGB, 0);
}

///////////////////////////////////////////////
float4 stdHDR_DownScale4x4(int aSampler, in float2 vScreenPosition)
{
  float4 sample = 0.0f;
  eStd_ForUnroll for (int i=0; i < 16; i++) {
    sample += stdTex2D(aSampler, vScreenPosition + uHDR_SampleOffsets[i]);
  }
  return sample / 16.0f;
}

///////////////////////////////////////////////
float4 stdHDR_DownScale2x2(int aSampler, in float2 vScreenPosition)
{
  float4 sample = 0.0f;
  eStd_ForUnroll for (int i = 0; i < 4; i++) {
    sample += stdTex2D(aSampler, vScreenPosition + uHDR_SampleOffsets[i]);
  }
  return sample / 4.0f;
}

///////////////////////////////////////////////
// Perform a high-pass filter on the source texture
float4 stdHDR_BrightPass(int aSamplerLit, int aSamplerLum, in float2 vScreenPosition)
{
  float4 vSample = stdTex2D(aSamplerLit, vScreenPosition);
  float  fAdaptedLum = stdTex2D(aSamplerLum, float2(0.5f, 0.5f)).x;

  // Determine what the pixel's value will be after tone-mapping occurs
  vSample.rgb *= HDR_MIDDLE_GRAY/(fAdaptedLum + 0.001f);

  // Subtract out dark pixels
  vSample.rgb -= HDR_BRIGHT_PASS_THRESHOLD;

  // Clamp to 0
  vSample = max(vSample, 0.0f);

  // Map the resulting value into the 0 to 1 range. Higher values for
  // kBrightPassOffset will isolate lights from illuminated scene
  // objects.
  vSample.rgb /= (HDR_BRIGHT_PASS_OFFSET+vSample);

  return vSample;
}

///////////////////////////////////////////////
// Sample the luminance of the source image using a kernal of sample
// points, and return a scaled image containing the log() of averages
float4 stdHDR_SampleLumInitial(int aSamplerLit, in float2 vScreenPosition)
{
  float3 vSample = 0.0f;
  float  fLogLumSum = 0.0f;

  eStd_ForUnroll for (int iSample = 0; iSample < 9; iSample++)
  {
    // Compute the sum of log(luminance) throughout the sample points
    vSample = stdTex2D(aSamplerLit, vScreenPosition+uHDR_SampleOffsets[iSample]);
    fLogLumSum += log(dot(vSample,kHDR_LuminanceVector)+0.0001f);
  }

  // Divide the sum to complete the average
  fLogLumSum /= 9;

  return float4(fLogLumSum, fLogLumSum, fLogLumSum, 1.0f);
}

///////////////////////////////////////////////
// Scale down the luminance texture by blending sample points
float4 stdHDR_SampleLumIterate(int aSamplerLit, float2 vScreenPosition)
{
  float fResampleSum = 0.0f;
  eStd_ForUnroll for (int iSample = 0; iSample < 16; iSample++)
  {
    // Compute the sum of luminance throughout the sample points
    fResampleSum += stdTex2D(aSamplerLit, vScreenPosition+uHDR_SampleOffsets[iSample]);
  }

  // Divide the sum to complete the average
  fResampleSum /= 16;

  return float4(fResampleSum, fResampleSum, fResampleSum, 1.0f);
}

///////////////////////////////////////////////
// Extract the average luminance of the image by completing the averaging
// and taking the exp() of the result
float4 stdHDR_SampleLumFinal(int aSamplerLit, in float2 vScreenPosition)
{
  float fResampleSum = 0.0f;

  eStd_ForUnroll for (int iSample = 0; iSample < 16; iSample++)
  {
    // Compute the sum of luminance throughout the sample points
    fResampleSum += stdTex2D(aSamplerLit, vScreenPosition+uHDR_SampleOffsets[iSample]);
  }

  // Divide the sum to complete the average, and perform an exp() to complete
  // the average luminance calculation
  fResampleSum = exp(fResampleSum/16);

  return float4(fResampleSum, fResampleSum, fResampleSum, 1.0f);
}

///////////////////////////////////////////////
// Calculate the luminance that the camera is current adapted to, using
// the most recented adaptation level, the current scene luminance, and
// the time elapsed since last calculated
float4 stdHDR_LumAdapt(int aSamplerLum, int aSamplerToneMap, in float2 vScreenPosition)
{
  float fAdaptedLum = stdTex2D(aSamplerLum, float2(0.5f, 0.5f)).r;
  float fCurrentLum = stdTex2D(aSamplerToneMap, float2(0.5f, 0.5f)).r;

  // The user's adapted luminance level is simulated by closing the gap between
  // adapted luminance and current luminance by 2% every frame, based on a
  // 30 fps rate. This is not an accurate model of human adaptation, which can
  // take longer than half an hour.
  float fNewAdaptation = fAdaptedLum + (fCurrentLum - fAdaptedLum) * (1 - pow(0.98f, HDR_ADAPTATION_SPEED * fpsTime.w));
  return float4(fNewAdaptation, fNewAdaptation, fNewAdaptation, 1.0f);
}

///////////////////////////////////////////////
float4 stdHDR_GaussBlur5x5(int aSamplerLum, in float2 vScreenPosition)
{
  float4 sample = 0.0f;

  eStd_ForUnroll for (int i = 0; i < 13; i++ ) {
    sample += uHDR_SampleWeights[i] * stdTex2D(aSamplerLum, vScreenPosition + uHDR_SampleOffsets[i]);
  }

  return sample;
}

///////////////////////////////////////////////
// Blur the source image along one axis using a gaussian
// distribution. Since gaussian blurs are separable, this shader is called
// twice; first along the horizontal axis, then along the vertical axis.
float4 stdHDR_Bloom(int aSampler, in float2 vScreenPosition)
{
  float4 vSample = 0.0f;
  float4 vColor = 0.0f;

  float2 vSamplePosition;

  // Perform a one-directional gaussian blur
  eStd_ForUnroll for (int iSample = 0; iSample < 15; iSample++)
  {
    vSamplePosition = vScreenPosition + uHDR_SampleOffsets[iSample];
    vColor = stdTex2D(aSampler, vSamplePosition);
    vSample += uHDR_SampleWeights[iSample]*vColor;
  }

  return vSample;
}

///////////////////////////////////////////////
float4 stdHDR_MergeTextures(float2 vScreenPosition, const int anFirstSampler, const int anSamplerCount)
{
  float4 vColor = 0.0f;

  eStd_ForUnroll for (int i = 0; i < anSamplerCount; ++i) {
    vColor += uHDR_SampleWeights[i]*tex2D(gAllSamplers[anFirstSampler+i],vScreenPosition);
  }

  return vColor;
}

///////////////////////////////////////////////
// Each star is composed of up to 8 lines, and each line is created by
// up to three passes of this shader, which samples from 8 points along
// the current line.
float4 stdHDR_Star(int aSampler, in float2 vScreenPosition)
{
  float4 vSample = 0.0f;
  float4 vColor = 0.0f;

  float2 vSamplePosition;

  // Sample from eight points along the star line
  eStd_ForUnroll for (int iSample = 0; iSample < 8; iSample++)
  {
    vSamplePosition = vScreenPosition + uHDR_SampleOffsets[iSample];
    vSample = stdTex2D(aSampler, vSamplePosition);
    vColor += uHDR_SampleWeights[iSample] * vSample;
  }

  return vColor;
}

///////////////////////////////////////////////
// For very low light conditions, the rods will dominate the perception
// of light, and therefore color will be desaturated and shifted
// towards blue.
float3 stdHDR_BlueShift(float3 aColor, float afLum)
{
  // Define a linear blending from -1.5 to 2.6 (log scale) which
  // determines the lerp amount for blue shift
  float fBlueShiftCoefficient = 1.0f - (afLum + 1.5)/4.1;
  fBlueShiftCoefficient = saturate(fBlueShiftCoefficient);

  // Lerp between current color and blue, desaturated copy
  float3 vRodColor = dot( (float3)aColor, kLuminanceVector ) * kHDR_BlueShiftVector;
  return lerp( (float3)aColor, vRodColor, fBlueShiftCoefficient );
}

///////////////////////////////////////////////
// Map the high range of color values into a range appropriate for
// display, taking into account the user's adaptation level, and selected
// values for for middle gray and white cutoff.
float3 stdHDR_ToneMapLinear(float3 aColor, float afLum)
{
  float3 ret = aColor;
  ret *= HDR_MIDDLE_GRAY/(afLum + 0.001f);
  ret /= (1.0f+ret);
  return ret;
}
float3 stdHDR_ToneMapReinhard(float3 aColor, float afLum)
{
  float3 ret = aColor;
  ret *= HDR_MIDDLE_GRAY/(afLum + 0.001f);
  ret /= (1.0f+ret);
  return ret;
}
float3 stdHDR_ToneMapReinhard2(float3 aColor, float afLum)
{
  float3 ret = aColor;
  ret *= HDR_MIDDLE_GRAY/(afLum + 0.001f);
  ret /= (1.0f+ret);
  return ret;
}
float3 stdHDR_ToneMapAdaptiveLog(float3 aColor, float afLum)
{
  float3 ret = aColor;
  ret *= HDR_MIDDLE_GRAY/(afLum + 0.001f);
  ret /= (1.0f+ret);
  return ret;
}

/// EOF //////////////////////////////////////////////////////////////////////////////////////
#endif // __STDHDR_CGH_A5B2945F_539F_4023_835B_6A509BAD191E__
